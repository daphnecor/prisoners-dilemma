{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80V_CBzzLMU1"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from typing import Dict, List, Tuple, Union\n",
    "from gym import Space, spaces\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from prisoners_dilemma import utils\n",
    "from prisoners_dilemma.env import PrisonersDilemmaEnv\n",
    "\n",
    "sns.set('notebook', font_scale=1.1, rc={'figure.figsize': (7, 4)})\n",
    "sns.set_style('ticks', rc={'figure.facecolor': 'none', 'axes.facecolor': 'none'})\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "matplotlib.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run experiments [standard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup config\n",
    "config = {\n",
    "    'num_simuls': 1,\n",
    "    'num_episodes': 50,\n",
    "    'num_agents': 2,\n",
    "    'num_actions': 2,\n",
    "    'verbose': False,\n",
    "    'init_type':'zeros',\n",
    "}\n",
    "\n",
    "config['payoffs'] = {\n",
    "    'reward_payoff': 2,\n",
    "    'tempta_payoff': 3,\n",
    "    'sucker_payoff': 0,\n",
    "    'punish_payoff': 1,\n",
    "}\n",
    "\n",
    "config['params'] = {\n",
    "    'alpha': np.array([0.1, 0.1]),\n",
    "    'eps': np.array([0.35, 0.35]),\n",
    "    'gamma': np.array([0.5, 0.5]),\n",
    "}\n",
    "\n",
    "# Run experiments\n",
    "q_traj_one, q_traj_two, rewards_seq, action_seq = utils.run_standard_ipd_exp(config)\n",
    "\n",
    "# Visualize trajectories and actions\n",
    "utils.make_q_vals_fig_standard(\n",
    "    action_seq=action_seq,\n",
    "    config=config,\n",
    "    q_traj_one=q_traj_one,\n",
    "    q_traj_two=q_traj_two,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run experiments [with observations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup config\n",
    "config = {\n",
    "    'num_simuls': 1,\n",
    "    'num_episodes': 500,\n",
    "    'num_agents': 2,\n",
    "    'num_actions': 2,\n",
    "    'verbose': False,\n",
    "    'init_type':'zeros',\n",
    "}\n",
    "\n",
    "config['payoffs'] = {\n",
    "    'reward_payoff': 2,\n",
    "    'tempta_payoff': 3,\n",
    "    'sucker_payoff': 0,\n",
    "    'punish_payoff': 1,\n",
    "}\n",
    "\n",
    "config['params'] = {\n",
    "    'alpha': np.array([0.1, 0.1]),\n",
    "    'eps': np.array([0.2, 0.2]),\n",
    "    'gamma': np.array([0.5, 0.5]),\n",
    "}\n",
    "\n",
    "\n",
    "q_traj_one, q_traj_two, rewards_seq, actions_seq = run_extended_ipd_exp(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(action_seq[:, 0], '.', alpha=.5)\n",
    "plt.plot(action_seq[:, 1], '^', alpha=.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Obtain combined action matrix\n",
    "# comb_act = utils.vis_action_matrix(action_seq)\n",
    "\n",
    "# sns.heatmap(\n",
    "#     comb_act,\n",
    "#     annot=False,\n",
    "#     cbar=False,\n",
    "#     cmap=['w', 'darkgreen'],\n",
    "#     vmin=0,\n",
    "#     vmax=1,\n",
    "#     yticklabels=['(D, D)', '(D, C)', '(C, D)', '(C, C)'],\n",
    "#     xticklabels=[],\n",
    "#     linewidths=.1,\n",
    "#     linecolor='k',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set('notebook', font_scale=1.1, rc={'figure.figsize': (10, 6)})\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, gridspec_kw={'height_ratios': [1, 1]})\n",
    "fig.suptitle(\n",
    "    f'ϵ=({config[\"params\"][\"eps\"][0]}, {config[\"params\"][\"eps\"][1]}), γ=({config[\"params\"][\"gamma\"][0]}, {config[\"params\"][\"gamma\"][1]})')\n",
    "\n",
    "# # Agent one\n",
    "# axs[0].set_title('Player 1')\n",
    "# agent_one_labels = ['$Q_{(D_1 | D_2)}$', '$Q_{(D_1 | C_2)}$', '$Q_{(C_1 | D_2)}$', '$Q_{(C_1 | C_2)}$',]\n",
    "# agent_one_colors = ['b', 'g', 'r', 'orange']\n",
    "# idx = 0\n",
    "# for action_i in range(config['num_actions']):\n",
    "#     for cond_act_i in range(config['num_actions']):\n",
    "#         axs[0].plot(\n",
    "#             q_traj_one[:, action_i, cond_act_i],\n",
    "#             color=agent_one_colors[idx], alpha=.8\n",
    "#         )\n",
    "#         axs[0].text(\n",
    "#             q_traj_one.shape[0],\n",
    "#             q_traj_one[-1, action_i, cond_act_i],\n",
    "#             agent_one_labels[idx],\n",
    "#             color=agent_one_colors[idx],\n",
    "#             fontsize=15,\n",
    "#             weight='bold',\n",
    "#             va='bottom',\n",
    "#         )\n",
    "#         idx += 1\n",
    "    \n",
    "axs[1].set_title('Player 2')d\n",
    "agent_one_labels = ['$Q_{(D_2 | D_1)}$', '$Q_{(D_2 | C_1)}$', '$Q_{(C_2 | D_1)}$', '$Q_{(C_2 | C_1)}$',]\n",
    "agent_one_colors = ['b', 'g', 'r', 'orange']\n",
    "idx = 0\n",
    "for action_i in range(config['num_actions']):\n",
    "    for cond_act_i in range(config['num_actions']):\n",
    "        axs[1].plot(\n",
    "            q_traj_two[:, action_i, cond_act_i],\n",
    "            color=agent_one_colors[idx], alpha=.8\n",
    "        )\n",
    "        axs[1].text(\n",
    "            q_traj_two.shape[0],\n",
    "            q_traj_two[-1, action_i, cond_act_i],\n",
    "            agent_one_labels[idx],\n",
    "            color=agent_one_colors[idx],\n",
    "            fontsize=15,\n",
    "            weight='bold',\n",
    "            va='bottom',\n",
    "        )\n",
    "        idx += 1\n",
    "\n",
    "axs[0].set_ylabel('Q-value')\n",
    "axs[1].set_ylabel('Q-value')\n",
    "axs[1].set_xlabel('Episode')\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "xraBLt1W0uOs",
    "Ik27P84pLDCS"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "d34d5eef7507bb13b430f5217be103884edd667ef694ed18d3f7943da64c9dae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
